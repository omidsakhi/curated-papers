# List of Curated Papers
Hello friends,

I'm excited to share with you a list of the most influential deep learning papers. I have selected these based on their impact in the community, my own interest in understanding the behaviour and psychology of artificial neural networks and the creative aspects of them. These papers have contributed greatly to the progress of deep learning research and have been invaluable resources for me during the development of our own product.

Please note that there are many other amazing papers out there, and I may have missed some that have been written by my own friends. So, my apologies in advance for any oversight, and please do let me know if there's a paper you think deserves a spot on the list.

But for now, let's focus on the papers that made the cut! Each one is packed with valuable insights, tips, and tricks that have helped me tackle challenging problems and make significant strides in my work.

Whether you're a seasoned researcher or just starting out in the field of deep learning, I believe that these papers will be a valuable resource for you. So, grab a cup of coffee and take some time to explore this list. I look forward to hearing your thoughts and sparking some interesting discussions in the comments.

Thanks for being a part of this amazing community and keep crushing it!

## Theory

| Year | Month | Title           |
| ------------- |-------------|-------------|
| 1998 | 03 | [Gradient-Based Learning Applied to Document Recognition](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf) |
| 2006 | 07 | [Reducing the Dimensionality of Data with Neural Networks](http://www.cs.toronto.edu/~hinton/absps/science.pdf) |
| 2010 |    | [Understanding the difficulty of training deep feedforward neural networks](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) |
| 2012 |    | [A Few Useful Things to Know about Machine Learning](https://www.astro.caltech.edu/~george/ay122/cacm12.pdf) |
| 2012 | 06 | [Improving neural networks by preventing co-adaptation of feature detectors](https://arxiv.org/abs/1207.0580) |
| 2013 |    | [on the importance of initialization and momentum in deep learning](https://www.cs.toronto.edu/~fritz/absps/momentum.pdf) |
| 2014 | 05 | [Deep Learning in Neural Networks: An Overview](https://arxiv.org/abs/1404.7828) |
| 2014 | 06 | [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf) |
| 2014 | 12 | [Neural Turing Machines](https://arxiv.org/abs/1410.5401) | 
| 2014 | 12 | [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980) | 
| 2014 | 12 | [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) |
| 2015 |    | [Deep learning](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf) |
| 2015 | 02 | [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167) |
| 2015 | 02 | [Human-level control through deep reinforcement learning](https://www.deepmind.com/publications/human-level-control-through-deep-reinforcement-learning) |
| 2015 | 03 | [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531) | 
| 2015 | 05 | [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597) |
| 2015 | 06 | [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) |
| 2015 | 09 | [Continuous control with deep reinforcement learning](https://arxiv.org/abs/1509.02971) |
| 2015 | 09 | [Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461) |
| 2015 | 12 | [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) |
| 2016 | 06 | [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/abs/1603.02754) | 
| 2016 | 08 | [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993) |
| 2016 | 09 | [Understanding deep learning requires rethinking generalization](https://arxiv.org/abs/1611.03530) | 
| 2017 | 03 | [Mask R-CNN](https://arxiv.org/abs/1703.06870) |
| 2017 | 08 | [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002) | 
| 2017 | 12 | [LightGBM: A Highly Efficient Gradient Boosting Decision Tree](https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html) |
| 2018 | 03 | [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635) |
| 2018 | 03 | [Group Normalization](https://arxiv.org/abs/1803.08494) |
| 2018 | 04 | [Partial Convolution based Padding](https://arxiv.org/abs/1811.11718) |
| 2018 | 05 | [Born Again Neural Networks](https://arxiv.org/abs/1805.04770) |
| 2018 | 06 | [Neural Ordinary Differential Equations](https://arxiv.org/abs/1806.07366) |
| 2018 | 11 | [Rethinking ImageNet Pre-training](https://arxiv.org/abs/1811.08883) |
| 2018 | 12 | [Graph neural networks: A review of methods and applications](https://arxiv.org/abs/1812.08434) |
| 2019 | 12 | [Deep Double Descent: Where Bigger Models and More Data Hurt](https://arxiv.org/abs/1912.02292) |
| 2019 | 12 | [Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data](https://arxiv.org/abs/1912.07768) |
| 2020 | 03 | [Autoencoders](https://arxiv.org/abs/2003.05991) |
| 2020 | 06 | [Hopfield Networks is All You Need](https://arxiv.org/abs/2008.02217) |

## Generative Models (VAE, GAN and Diffusion Models)

### GAN
| Year | Month | Title           |
| ------------- |-------------|-------------|
| 2014 | 06 | [Generative Adversarial Nets](https://arxiv.org/abs/1406.2661) |
| 2014 | 10 | [Neural Turing Machines](https://arxiv.org/abs/1410.5401) |
| 2014 | 11 | [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) |
| 2015 | 11 | [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)](https://arxiv.org/abs/1511.06434) |
| 2016 | 06 | [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498) |
| 2016 | 09 | [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (SRGAN)](https://arxiv.org/abs/1609.04802) |
| 2016 | 11 | [Image-to-Image Translation with Conditional Adversarial Networks (Pix2Pix)](https://arxiv.org/abs/1611.07004) | 
| 2017 | 01 | [Wasserstein GAN](https://arxiv.org/abs/1701.07875) |
| 2017 | 03 | [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)](https://arxiv.org/abs/1703.10593) | 
| 2017 | 03 | [BEGAN: Boundary Equilibrium Generative Adversarial Networks](https://arxiv.org/abs/1703.10717) | 
| 2017 | 03 | [Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028) |
| 2017 | 10 | [Progressive Growing of GANs for Improved Quality, Stability, and Variation (ProGAN)](https://arxiv.org/abs/1710.10196) |
| 2017 | 11 | [StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://arxiv.org/abs/1711.09020) |
| 2018 | 01 | [Which Training Methods for GANs do actually Converge?](https://arxiv.org/abs/1801.04406) |
| 2018 | 02 | [Spectral Normalization for Generative Adversarial Networks](https://arxiv.org/abs/1802.05957) |
| 2018 | 04 | [A Fully Progressive Approach to Single-Image Super-Resolution (ProGanSR)](https://arxiv.org/abs/1804.02900) |
| 2018 | 05 | [Self-Attention Generative Adversarial Networks](https://arxiv.org/abs/1805.08318) | 
| 2018 | 06 | [The relativistic discriminator: a key element missing from standard GAN](https://arxiv.org/abs/1807.00734) |
| 2018 | 09 | [Large Scale GAN Training for High Fidelity Natural Image Synthesis (BigGAN)](https://arxiv.org/abs/1809.11096) |
| 2018 | 12 | [A Style-Based Generator Architecture for Generative Adversarial Networks (StyleGAN)](https://arxiv.org/abs/1812.04948) |
| 2018 | 09 | [ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks](https://arxiv.org/abs/1809.00219) |
| 2019 | 12 | [Analyzing and Improving the Image Quality of StyleGAN (StyleGAN2)](https://arxiv.org/abs/1912.04958) |
| 2021 | 06 | [Alias-Free Generative Adversarial Networks (StyleGAN3)](https://arxiv.org/abs/2106.12423) |
| 2023 | 01 | [StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis](https://arxiv.org/abs/2301.09515) |
| 2023 | 03 | [GigaGAN: Scaling up GANs for Text-to-Image Synthesis](https://arxiv.org/abs/2303.05511) |

### Diffusion Models
| Year | Month | Title | Resources |
| ------------- |-------------|-------------|-------------|
| 2010 | 12 | [A Connection Between Score Matching and Denoising Autoencoders](https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf) ||
| 2013 | 12 | [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114) ||
| 2015 | 03 | [Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://arxiv.org/abs/1503.03585) ||
| 2016 | 06 | [Conditional Image Generation with PixelCNN Decoders (PixelCNN)](https://arxiv.org/abs/1606.05328) ||
| 2017 | 06 | [Attention Is All You Need](https://arxiv.org/abs/1706.03762) ||
| 2017 | 11 | [Neural Discrete Representation Learning (VQVAE)](https://arxiv.org/abs/1711.00937) ||
| 2017 | 01 | [Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications (PixelCNN++)](https://arxiv.org/abs/1701.05517) | [GitHub](https://github.com/openai/pixel-cnn) |
| 2019 | 06 | [Generating Diverse High-Fidelity Images with VQ-VAE-2](https://arxiv.org/abs/1906.00446) ||
| 2019 | 07 | [Generative Modeling by Estimating Gradients of the Data Distribution](https://arxiv.org/abs/1907.05600) || 
| 2020 | 06 | [Denoising Diffusion Probabilistic Models (DDPM)](https://arxiv.org/abs/2006.11239) | [GitHub](https://hojonathanho.github.io/diffusion/) |
| 2020 | 10 | [Denoising Diffusion Implicit Models (DDIM)](https://arxiv.org/abs/2010.02502) | [GitHub](https://github.com/ermongroup/ddim) |
| 2020 | 10 | [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)](https://arxiv.org/abs/2010.11929) | [On-HF](https://huggingface.co/docs/transformers/model_doc/vit) |
| 2020 | 11 | [Score-Based Generative Modeling through Stochastic Differential Equations](https://arxiv.org/abs/2011.13456) | [GitHub](https://github.com/yang-song/score_sde) |
| 2021 | 01 | [How to Train Your Energy-Based Models](https://arxiv.org/abs/2101.03288) ||
| 2021 | 02 | [Learning Transferable Visual Models From Natural Language Supervision (CLIP)](https://arxiv.org/abs/2103.00020) ||
| 2021 | 05 | [Diffusion Models Beat GANs on Image Synthesis (Guided Diffusion)](https://arxiv.org/abs/2105.05233) | [GitHub](https://github.com/openai/guided-diffusion) |
| 2021 | 06 | [Low-Rank Adaptation of Large Language Models (LoRA)](https://arxiv.org/abs/2106.09685) | [HF-Training](https://huggingface.co/docs/diffusers/training/lora) |
| 2021 | 12 | [High-Resolution Image Synthesis with Latent Diffusion Models (Stable Diffusion)](https://arxiv.org/abs/2112.10752) | [GitHub](https://github.com/CompVis/latent-diffusion) |
| 2021 | 12 | [Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models (GLIDE)](https://arxiv.org/abs/2112.10741) | [GitHub](https://github.com/openai/glide-text2im) |
| 2022 | 02 | [Pseudo Numerical Methods for Diffusion Models on Manifolds (PNDM)](https://arxiv.org/abs/2202.09778) | [HF-Pipeline](https://huggingface.co/docs/diffusers/api/pipelines/pndm) |
| 2022 | 04 | [Hierarchical Text-Conditional Image Generation with CLIP Latents (DALL-E 2)](https://cdn.openai.com/papers/dall-e-2.pdf) | [Project Page](https://openai.com/dall-e-2) |
| 2022 | 05 | [Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding (Imagen)](https://arxiv.org/abs/2205.11487) | [Project Page](https://imagen.research.google/) |
| 2022 | 06 | [Elucidating the Design Space of Diffusion-Based Generative Models (EulerDiscrete)](https://arxiv.org/abs/2206.00364) | [HF-Schedulers](https://huggingface.co/docs/diffusers/main/en/api/schedulers/euler) |
| 2022 | 06 | [DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps](https://arxiv.org/abs/2206.00927) ||
| 2022 | 08 | [Understanding Diffusion Models: A Unified Perspective](https://arxiv.org/abs/2208.11970) ||
| 2022 | 11 | [Null-text Inversion for Editing Real Images using Guided Diffusion Models](https://arxiv.org/abs/2211.09794) | [YouTube](https://www.youtube.com/watch?v=qzTlzrMWU2M) |
| 2022 | 11 | [DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models](https://arxiv.org/abs/2211.01095) | [HF-Scheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/multistep_dpm_solver) |
| 2022 | 12 | [Scalable Diffusion Models with Transformers (DiT)](https://arxiv.org/abs/2212.09748) | [Project Page](https://www.wpeebles.com/DiT) |
| 2022 | 12 | [Reproducible scaling laws for contrastive language-image learning](https://arxiv.org/abs/2212.07143) ||
| 2023 | 02 | [Adding Conditional Control to Text-to-Image Diffusion Models (ControlNET)](https://arxiv.org/abs/2302.05543) | [HF-ControlNet](https://huggingface.co/docs/diffusers/main/en/using-diffusers/controlnet) |
| 2023 | 02 | [UniPC: A Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models](https://arxiv.org/abs/2302.04867) | [HF-Scheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/unipc) |
| 2023 | 03 | [MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation](https://arxiv.org/abs/2302.08113) | [HF-Pipeline](https://huggingface.co/docs/diffusers/api/pipelines/panorama) |
| 2023 | 04 | [Generative Novel View Synthesis with 3D-Aware Diffusion Models](https://arxiv.org/abs/2304.02602) | [Project Page](https://nvlabs.github.io/genvs/) |
| 2023 | 07 | [Improving Latent Diffusion Models for High-Resolution Image Synthesis (SDXL)](https://arxiv.org/abs/2307.01952) | [HF-Model](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) |

## Others

| Year | Month | Title           |
| ------------- |-------------|-------------|
| 2012 | 12 | [ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) |
| 2013 | 12 | [Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602) |
| 2014 | 09 | [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) |
| 2015 | 02 | [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044) |
| 2015 | 08 | [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) |
| 2016 | 01 | [Mastering the game of Go with deep neural networks and tree search](https://www.deepmind.com/publications/mastering-the-game-of-go-with-deep-neural-networks-tree-search) |
| 2016 | 03 | [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155) |
| 2016 | 09 | [WaveNet: A Generative Model for Raw Audio](https://arxiv.org/abs/1609.03499) |
| 2017 | 01 | [UNet++: A Nested U-Net Architecture for Medical Image Segmentation](https://arxiv.org/abs/1807.10165) |
| 2017 | 06 | [Unsupervised Body Part Regression via Spatially Self-ordering Convolutional Neural Networks](https://arxiv.org/abs/1707.03891) | 
| 2018 | 04 | [Image Inpainting for Irregular Holes Using Partial Convolutions](https://arxiv.org/abs/1804.07723) |
| 2018 | 07 | [IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis](https://arxiv.org/abs/1807.06358) |
| 2018 | 07 | [Glow: Generative Flow with Invertible 1x1 Convolutions](https://arxiv.org/abs/1807.03039) |
| 2018 | 10 | [Noise2Noise: Learning Image Restoration without Clean Data](https://arxiv.org/abs/1803.04189) |
| 2019 | 01 | [Panoptic Feature Pyramid Networks](https://arxiv.org/abs/1901.02446) |
| 2019 | 01 | [High-Quality Self-Supervised Deep Image Denoising](https://arxiv.org/abs/1901.10277) |
| 2019 | 03 | [Semantic Image Synthesis with Spatially-Adaptive Normalization](https://arxiv.org/abs/1903.07291) |
| 2020 | 03 | [PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models](https://arxiv.org/abs/2003.03808) |
| 2020 | 03 | [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934) |
| 2020 | 12 | [nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation](https://github.com/MIC-DKFZ/nnUNet) |
| 2022 | 01 | [Instant Neural Graphics Primitives with a Multiresolution Hash Encoding](https://arxiv.org/abs/2201.05989) |
